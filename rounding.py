import random
from random_replacement import ro_uvr,OBJ_dict
from cvxopt import matrix
import time
import argparse
from pyspark import SparkContext, SparkConf
from helpers import write
from Toplogy_gen import Problem, Demand
import os

def SwapRound(beta_bases_tpl,v):
     
    def MergeBases(beta1, B1, beta2, B2,random_generator):
        def subtract(B1,B2):
            """Return B1-B2"""
            a= set(B1)
            b=set(B2)
            return tuple(a.difference(b))
        k=0
        while set(B1)!=set(B2):
            B1_slsh_B2 = subtract(B1,B2)
            B2_slsh_B1 = subtract(B2,B1)
            i = B1_slsh_B2[0]
            j = B2_slsh_B1[0]
            RN = random_generator.random()
            if RN<beta1/(beta1+beta2):
                B2 = subtract(B2,(j,))+(i,)
            else:
                B1 = subtract(B1,(i,))+(j,)
            k+=1
        return B1
    RG = random.Random()
    RG.seed(v)
    p = len(beta_bases_tpl)
    C_new = beta_bases_tpl[0][0]
    beta1 = beta_bases_tpl[0][1]
    for k in range(p-1):
        beta2 = beta_bases_tpl[k+1][1]
        B2 = beta_bases_tpl[k+1][0]
        C_old = C_new
         
        C_new = MergeBases(beta1=beta1,B1=C_old,beta2=beta2,B2=B2,random_generator=RG)
        beta1 = beta1 +beta2
    return C_new


def distributed_rounding(input,P):
    def flatten_dictionary(dict):
        l = []
        for v in dict:
           l.append((v,dict[v]))
        return l
    def make_unique(l):
        l.sort()
        return tuple(l)
    f = open(input, 'r')
    base_list= eval(f.readline())
    f.close()
    conf = (SparkConf()
         .setMaster("local[40]")
         .setAppName("My app")
         .set("spark.executor.memory", "100g"))
    sc = SparkContext(conf=conf)
    sc.setLogLevel("ERROR")
    RDD_bases = sc.parallelize(base_list).flatMap(flatten_dictionary).mapValues(lambda base_list:make_unique(base_list))\
                                         .map(lambda (v,tpl_base):((v,tpl_base),1)).reduceByKey(lambda x,y:x+y, P)\
                                         .map(lambda ((v,base_tpl),cnt):(v,[(base_tpl,cnt)])).reduceByKey(lambda x,y:x+y, P)\
                                         .map(lambda (v,base_tpls):(v,(base_tpls,v))).partitionBy(P)\
             			         .mapValues(lambda (base_tpls,v):SwapRound(base_tpls,v)).cache()
                                         
    return RDD_bases 
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description = 'Simulate the Swap Rounding Alg.',formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument('input',help = 'The fractional solution generated by Cont_Greedy.')
    parser.add_argument('problem_instance')
    parser.add_argument('output')
    args  = parser.parse_args()
    input = "BASE/"+args.input
    input_problem = "INPUT_NEW/"+args.problem_instance
    P = Problem.unpickle_cls(input_problem)
    capacities = P.capacities
    dem_items=[]
    for demand in P.demands:
         item = demand.item
         dem_items.append(item)
    V,I = (len(P.capacities),len(set(dem_items)))
    RDD_bases = distributed_rounding(input,56)
    base_out  = RDD_bases.collect()
    X = matrix(0,(V,I))
    tstart = time.time()
    for (v,items) in base_out:
         for item in items:
             X[v,item] = 1
    print X
    ro_uvr_dic = ro_uvr(P,X)
    OBJ =  OBJ_dict(P,ro_uvr_dic)
    elapsed = time.time()-tstart
    print "OBJ is %f and time taken is %f" %(P.cost-OBJ,elapsed)
    track = [P.cost]
    track += [(elapsed,P.cost-OBJ)]

    dir_rounded = "ROUNDED/"
    if not os.path.exists(dir_rounded):
        os.mkdir(dir_rounded)
    rounded = dir_rounded+args.output
    write(rounded,track)
